{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "163784cd-3137-4867-97d5-609f27107851",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Calculate stats for each numerical experiment for each ensembles\n",
    "\n",
    "- First, calculate stat for each ensemble\n",
    "- Second, calculate mean stat over all ensembles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "54fbedb7-918c-46da-8ad6-9df236533523",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/xinchenhe_umass_edu/.conda/envs/laketemp/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import glob\n",
    "import geopandas as gpd\n",
    "from p_tqdm import p_map\n",
    "from functools import partial\n",
    "from datetime import date\n",
    "from scipy import stats\n",
    "os.chdir(\"..\")\n",
    "import tools.marineHeatWaves as mhw\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "20f365e5-82e6-4471-b522-bd0532fa2e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data paths to simulated water temperature\n",
    "a2w_full_sim_dir = \"/nas/cee-hydro/laketemp_bias/simulations/a2w_full_sim\"\n",
    "a2w_cloud_sim_dir = \"/nas/cee-hydro/laketemp_bias/simulations/a2w_cloud_sim\"\n",
    "lstm_full_sim_dir = \"/nas/cee-hydro/laketemp_bias/simulations/lstm_full_sim\"\n",
    "lstm_cloud_sim_dir = \"/nas/cee-hydro/laketemp_bias/simulations/lstm_cloud_sim\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "12cc9295-7bc1-47fa-8548-59ce35dbc85d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_period = pd.date_range(\"2003-01-01\", \"2017-12-31\")\n",
    "val_period = pd.date_range(\"2018-01-01\", \"2023-12-31\")\n",
    "total_period = pd.date_range(\"2003-01-01\", \"2023-12-31\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3d930f8a-c6f9-4db3-8006-06286a08a0b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NAME</th>\n",
       "      <th>COUNTRY</th>\n",
       "      <th>LAT CENTRE</th>\n",
       "      <th>LON CENTRE</th>\n",
       "      <th>MAX DISTANCE TO LAND (KM)</th>\n",
       "      <th>LAT MIN BOX</th>\n",
       "      <th>LAT MAX BOX</th>\n",
       "      <th>LON MIN BOX</th>\n",
       "      <th>LON MAX BOX</th>\n",
       "      <th>ID in GLOBOLAKES 1000 MASK</th>\n",
       "      <th>ID in CGLOPS MASK</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CCI ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>799</th>\n",
       "      <td>Hawizeh marshes</td>\n",
       "      <td>Iraq;Iran Islamic Republic of</td>\n",
       "      <td>31.3792</td>\n",
       "      <td>47.7236</td>\n",
       "      <td>1.0</td>\n",
       "      <td>31.2042</td>\n",
       "      <td>31.4292</td>\n",
       "      <td>47.6042</td>\n",
       "      <td>47.7792</td>\n",
       "      <td>799;</td>\n",
       "      <td>799;</td>\n",
       "      <td>POINT (47.7236 31.3792)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3114</th>\n",
       "      <td>loch Ness</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>57.3792</td>\n",
       "      <td>-4.3597</td>\n",
       "      <td>1.2</td>\n",
       "      <td>57.1042</td>\n",
       "      <td>57.4542</td>\n",
       "      <td>-4.7125</td>\n",
       "      <td>-4.2958</td>\n",
       "      <td>3114;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>POINT (-4.3597 57.3792)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7889</th>\n",
       "      <td>lough Melvin</td>\n",
       "      <td>Ireland;United Kingdom</td>\n",
       "      <td>54.4208</td>\n",
       "      <td>-8.1264</td>\n",
       "      <td>1.3</td>\n",
       "      <td>54.3625</td>\n",
       "      <td>54.4958</td>\n",
       "      <td>-8.2875</td>\n",
       "      <td>-8.0542</td>\n",
       "      <td>7889;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>POINT (-8.1264 54.4208)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2516</th>\n",
       "      <td>loch Lomond</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>56.0708</td>\n",
       "      <td>-4.5792</td>\n",
       "      <td>1.5</td>\n",
       "      <td>55.9708</td>\n",
       "      <td>56.3458</td>\n",
       "      <td>-4.7542</td>\n",
       "      <td>-4.4792</td>\n",
       "      <td>2516;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>POINT (-4.5792 56.0708)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12262</th>\n",
       "      <td>loch Leven</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>56.2042</td>\n",
       "      <td>-3.3792</td>\n",
       "      <td>1.5</td>\n",
       "      <td>56.1375</td>\n",
       "      <td>56.2625</td>\n",
       "      <td>-3.4542</td>\n",
       "      <td>-3.2958</td>\n",
       "      <td>12262;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>POINT (-3.3792 56.2042)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    NAME                        COUNTRY  LAT CENTRE  \\\n",
       "CCI ID                                                                \n",
       "799      Hawizeh marshes  Iraq;Iran Islamic Republic of     31.3792   \n",
       "3114           loch Ness                 United Kingdom     57.3792   \n",
       "7889        lough Melvin         Ireland;United Kingdom     54.4208   \n",
       "2516         loch Lomond                 United Kingdom     56.0708   \n",
       "12262         loch Leven                 United Kingdom     56.2042   \n",
       "\n",
       "        LON CENTRE  MAX DISTANCE TO LAND (KM)  LAT MIN BOX  LAT MAX BOX  \\\n",
       "CCI ID                                                                    \n",
       "799        47.7236                        1.0      31.2042      31.4292   \n",
       "3114       -4.3597                        1.2      57.1042      57.4542   \n",
       "7889       -8.1264                        1.3      54.3625      54.4958   \n",
       "2516       -4.5792                        1.5      55.9708      56.3458   \n",
       "12262      -3.3792                        1.5      56.1375      56.2625   \n",
       "\n",
       "        LON MIN BOX  LON MAX BOX ID in GLOBOLAKES 1000 MASK ID in CGLOPS MASK  \\\n",
       "CCI ID                                                                          \n",
       "799         47.6042      47.7792                       799;              799;   \n",
       "3114        -4.7125      -4.2958                      3114;               NaN   \n",
       "7889        -8.2875      -8.0542                      7889;               NaN   \n",
       "2516        -4.7542      -4.4792                      2516;               NaN   \n",
       "12262       -3.4542      -3.2958                     12262;               NaN   \n",
       "\n",
       "                       geometry  \n",
       "CCI ID                           \n",
       "799     POINT (47.7236 31.3792)  \n",
       "3114    POINT (-4.3597 57.3792)  \n",
       "7889    POINT (-8.1264 54.4208)  \n",
       "2516    POINT (-4.5792 56.0708)  \n",
       "12262   POINT (-3.3792 56.2042)  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load cci lakes\n",
    "cci_lake_list = pd.read_csv(\"data/cci_lakes_hydrolake_depth.csv\")[\"CCI ID\"].to_numpy()\n",
    "cci_lakes = pd.read_csv(\"data/ESA_CCI_static_lake_mask_v2_1km_UoR_metadata_fv2.1_06Oct2021_4laketemp.csv\", index_col=0).loc[cci_lake_list]\n",
    "cci_lakes_gdf = gpd.GeoDataFrame(cci_lakes, geometry=gpd.points_from_xy(cci_lakes['LON CENTRE'], cci_lakes['LAT CENTRE']),\n",
    "                                crs=\"epsg:4326\")\n",
    "cci_lakes_gdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3abd0280-4ef0-4d13-a451-ee2aab2f964e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_warmest_month_mean(df):\n",
    "    \"\"\"\n",
    "    1. Find the warmest month for each year.\n",
    "    2. Calculate the average temperature of the warmest months.\n",
    "    \"\"\"\n",
    "    # monthly mean across df period\n",
    "    monthly_temperature = df.resample(\"ME\").mean()\n",
    "    # for each year, find the warmest month mean temperature\n",
    "    # then calculate mean across the df period\n",
    "    warmest_month_temperature = monthly_temperature.groupby(monthly_temperature.index.year).max().mean()\n",
    "    return warmest_month_temperature\n",
    "\n",
    "def cal_coldest_month_mean(df):\n",
    "    \"\"\"\n",
    "    1. Find the coldest month for each year.\n",
    "    2. Calculate the average temperature of the coldest months.\n",
    "    \"\"\"\n",
    "    # monthly mean across df period\n",
    "    monthly_temperature = df.resample(\"ME\").mean()\n",
    "    # for each year, find the warmest month mean temperature\n",
    "    # then calculate mean across the df period\n",
    "    coldest_month_temperature = monthly_temperature.groupby(monthly_temperature.index.year).min().mean()\n",
    "    return coldest_month_temperature\n",
    "\n",
    "def cal_mhw_stats(df):\n",
    "    '''\n",
    "    A function to calculate the marine heat wave stats\n",
    "    \n",
    "    return number of heat wave events, averaged intensity, averaged duration. They are all averaged across ensembles.\n",
    "    '''\n",
    "    \n",
    "    # from the df index and turn them into coordinal and save as variable t\n",
    "    t = df.index.map(lambda x: x.toordinal()).to_numpy()\n",
    "    \n",
    "    # get the ensemble number\n",
    "    # in our study, it's 10\n",
    "    ensemble_num = len(df.columns)\n",
    "    \n",
    "    # we look at three major metrics\n",
    "    n_events = [] # number of heat wave events\n",
    "    avg_intensity = [] # averaged maximum intensity across all heat wave events\n",
    "    avg_duration = [] # duration\n",
    "    \n",
    "    for i in range(ensemble_num):\n",
    "        # calculate the heat wave stats for each ensemble\n",
    "        mhws, clim = mhw.detect(t, df.iloc[:, i].to_numpy().ravel())\n",
    "        n_events.append(mhws[\"n_events\"])\n",
    "        avg_intensity.append(np.mean(mhws[\"intensity_mean\"]))\n",
    "        avg_duration.append(np.mean(mhws[\"duration\"]))\n",
    "    \n",
    "    # average across ensembles\n",
    "    avg_n_events = np.mean(n_events)\n",
    "    avg_avg_intensity = np.mean(avg_intensity)\n",
    "    avg_avg_duration = np.mean(avg_duration)\n",
    "    \n",
    "    return avg_n_events, avg_avg_intensity, avg_avg_duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dcc0f224-e44e-433d-aaeb-7d39d00766ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_ice_days(df, \n",
    "                 threshold = 0.76):\n",
    "    '''\n",
    "    A function to calculate number of days covered by ice\n",
    "    \n",
    "    Ice-cover: temperature < threshold\n",
    "    \n",
    "    Threshold is determined by the maximum RMSE during ice-covered period across study lakes\n",
    "    '''\n",
    "    # create a true/false dataframe\n",
    "    df_ice = df <= threshold\n",
    "    \n",
    "    # sum on each year and calculate the mean across different ensembles\n",
    "    ice_days = df_ice.groupby(df_ice.index.year).sum().mean()\n",
    "    \n",
    "    return ice_days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc7e3ab7-3ce7-40ac-89f4-06c49c404c93",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f594e6dc-0b9c-4879-9f3f-1132ddc4f7e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_stat(lake_id, period, return_wl_df = False):\n",
    "    # air2water, full\n",
    "    a2w_full_sim = pd.read_csv(f\"{a2w_full_sim_dir}/{lake_id}.csv\", index_col=0, parse_dates=True).loc[period]\n",
    "    a2w_full_sim_mean = a2w_full_sim.mean().mean()\n",
    "    a2w_full_sim_warmest_month_mean = cal_warmest_month_mean(a2w_full_sim).mean()\n",
    "    a2w_full_sim_coldest_month_mean = cal_coldest_month_mean(a2w_full_sim).mean()\n",
    "    a2w_full_sim_ice_days_0 = cal_ice_days(a2w_full_sim, threshold=0).mean()\n",
    "    a2w_full_sim_ice_days_076 = cal_ice_days(a2w_full_sim, threshold=0.76).mean()\n",
    "\n",
    "    # air2water, cloud\n",
    "    a2w_cloud_sim = pd.read_csv(f\"{a2w_cloud_sim_dir}/{lake_id}.csv\", index_col=0, parse_dates=True).loc[period]\n",
    "    a2w_cloud_sim_mean = a2w_cloud_sim.mean().mean()\n",
    "    a2w_cloud_sim_warmest_month_mean = cal_warmest_month_mean(a2w_cloud_sim).mean()\n",
    "    a2w_cloud_sim_coldest_month_mean = cal_coldest_month_mean(a2w_cloud_sim).mean()\n",
    "    a2w_cloud_sim_ice_days_0 = cal_ice_days(a2w_cloud_sim, threshold=0).mean()\n",
    "    a2w_cloud_sim_ice_days_076 = cal_ice_days(a2w_cloud_sim, threshold=0.76).mean()\n",
    "\n",
    "    # LSTM, full\n",
    "    lstm_full_sim = pd.read_csv(f\"{lstm_full_sim_dir}/{lake_id}.csv\", index_col=0, parse_dates=True).loc[period]\n",
    "    lstm_full_sim_mean = lstm_full_sim.mean().mean()\n",
    "    lstm_full_sim_warmest_month_mean = cal_warmest_month_mean(lstm_full_sim).mean()\n",
    "    lstm_full_sim_coldest_month_mean = cal_coldest_month_mean(lstm_full_sim).mean()\n",
    "    lstm_full_sim_ice_days_0 = cal_ice_days(lstm_full_sim, threshold=0).mean()\n",
    "    lstm_full_sim_ice_days_076 = cal_ice_days(lstm_full_sim, threshold=0.76).mean()\n",
    "\n",
    "    # LSTM, cloud\n",
    "    lstm_cloud_sim = pd.read_csv(f\"{lstm_cloud_sim_dir}/{lake_id}.csv\", index_col=0, parse_dates=True).loc[period]\n",
    "    lstm_cloud_sim_mean = lstm_cloud_sim.mean().mean()\n",
    "    lstm_cloud_sim_warmest_month_mean = cal_warmest_month_mean(lstm_cloud_sim).mean()\n",
    "    lstm_cloud_sim_coldest_month_mean = cal_coldest_month_mean(lstm_cloud_sim).mean()\n",
    "    lstm_cloud_sim_ice_days_0 = cal_ice_days(lstm_cloud_sim, threshold=0).mean()\n",
    "    lstm_cloud_sim_ice_days_076 = cal_ice_days(lstm_cloud_sim, threshold=0.76).mean()\n",
    "    \n",
    "    \n",
    "    # t-test between full and cloud for Air2Water\n",
    "    a2w_pvalue_mean = stats.ttest_ind(a2w_full_sim.mean(), a2w_cloud_sim.mean(), nan_policy='omit').pvalue\n",
    "    a2w_pvalue_warmest_month_mean = stats.ttest_ind(cal_warmest_month_mean(a2w_full_sim), cal_warmest_month_mean(a2w_cloud_sim), nan_policy='omit').pvalue\n",
    "    a2w_pvalue_coldest_month_mean = stats.ttest_ind(cal_coldest_month_mean(a2w_full_sim), cal_coldest_month_mean(a2w_cloud_sim), nan_policy='omit').pvalue\n",
    "    a2w_pvalue_ice_days_0 = stats.ttest_ind(cal_ice_days(a2w_full_sim, threshold=0), cal_ice_days(a2w_cloud_sim, threshold=0), nan_policy='omit').pvalue\n",
    "    a2w_pvalue_ice_days_076 = stats.ttest_ind(cal_ice_days(a2w_full_sim, threshold=0.76), cal_ice_days(a2w_cloud_sim, threshold=0.76), nan_policy='omit').pvalue\n",
    "\n",
    "    # t-test between full and cloud for LSTM\n",
    "    lstm_pvalue_mean = stats.ttest_ind(lstm_full_sim.mean(), lstm_cloud_sim.mean(), nan_policy='omit').pvalue\n",
    "    lstm_pvalue_warmest_month_mean = stats.ttest_ind(cal_warmest_month_mean(lstm_full_sim), cal_warmest_month_mean(lstm_cloud_sim), nan_policy='omit').pvalue\n",
    "    lstm_pvalue_coldest_month_mean = stats.ttest_ind(cal_coldest_month_mean(lstm_full_sim), cal_coldest_month_mean(lstm_cloud_sim), nan_policy='omit').pvalue\n",
    "    lstm_pvalue_ice_days_0 = stats.ttest_ind(cal_ice_days(lstm_full_sim, threshold=0), cal_ice_days(lstm_cloud_sim, threshold=0), nan_policy='omit').pvalue\n",
    "    lstm_pvalue_ice_days_076 = stats.ttest_ind(cal_ice_days(lstm_full_sim, threshold=0.76), cal_ice_days(lstm_cloud_sim, threshold=0.76), nan_policy='omit').pvalue\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Compute differences between cloud and full\n",
    "    a2w_diff_mean = a2w_cloud_sim_mean - a2w_full_sim_mean\n",
    "    a2w_diff_warmest_mean = a2w_cloud_sim_warmest_month_mean - a2w_full_sim_warmest_month_mean\n",
    "    a2w_diff_ice_days_0 = a2w_cloud_sim_ice_days_0 - a2w_full_sim_ice_days_0\n",
    "    a2w_diff_ice_days_076 = a2w_cloud_sim_ice_days_076 - a2w_full_sim_ice_days_076\n",
    "\n",
    "    lstm_diff_mean = lstm_cloud_sim_mean - lstm_full_sim_mean\n",
    "    lstm_diff_warmest_mean = lstm_cloud_sim_warmest_month_mean - lstm_full_sim_warmest_month_mean\n",
    "    lstm_diff_ice_days_0 = lstm_cloud_sim_ice_days_0 - lstm_full_sim_ice_days_0\n",
    "    lstm_diff_ice_days_076 = lstm_cloud_sim_ice_days_076 - lstm_full_sim_ice_days_076\n",
    "    \n",
    "    # Build stat dataframe\n",
    "    stat_df = pd.DataFrame([[\n",
    "        # Air2Water full\n",
    "        a2w_full_sim_mean, a2w_full_sim_warmest_month_mean, a2w_full_sim_coldest_month_mean,\n",
    "        a2w_full_sim_ice_days_0, a2w_full_sim_ice_days_076,\n",
    "\n",
    "        # Air2Water cloud\n",
    "        a2w_cloud_sim_mean, a2w_cloud_sim_warmest_month_mean, a2w_cloud_sim_coldest_month_mean,\n",
    "        a2w_cloud_sim_ice_days_0, a2w_cloud_sim_ice_days_076,\n",
    "\n",
    "        # Air2Water difference\n",
    "        a2w_diff_mean, a2w_diff_warmest_mean, a2w_diff_ice_days_0, a2w_diff_ice_days_076,\n",
    "\n",
    "        # LSTM full\n",
    "        lstm_full_sim_mean, lstm_full_sim_warmest_month_mean, lstm_full_sim_coldest_month_mean,\n",
    "        lstm_full_sim_ice_days_0, lstm_full_sim_ice_days_076,\n",
    "\n",
    "        # LSTM cloud\n",
    "        lstm_cloud_sim_mean, lstm_cloud_sim_warmest_month_mean, lstm_cloud_sim_coldest_month_mean,\n",
    "        lstm_cloud_sim_ice_days_0, lstm_cloud_sim_ice_days_076,\n",
    "\n",
    "        # LSTM difference\n",
    "        lstm_diff_mean, lstm_diff_warmest_mean, lstm_diff_ice_days_0, lstm_diff_ice_days_076,\n",
    "\n",
    "        # Air2Water p-values\n",
    "        a2w_pvalue_mean, a2w_pvalue_warmest_month_mean, a2w_pvalue_coldest_month_mean,\n",
    "        a2w_pvalue_ice_days_0, a2w_pvalue_ice_days_076,\n",
    "\n",
    "        # LSTM p-values\n",
    "        lstm_pvalue_mean, lstm_pvalue_warmest_month_mean, lstm_pvalue_coldest_month_mean,\n",
    "        lstm_pvalue_ice_days_0, lstm_pvalue_ice_days_076,\n",
    "    ]], index=[lake_id], columns=[\n",
    "        # Air2Water full\n",
    "        \"a2w_mean\", \"a2w_warmest_mean\", \"a2w_coldest_mean\", \n",
    "        \"a2w_ice_days_0\", \"a2w_ice_days_076\",\n",
    "\n",
    "        # Air2Water cloud\n",
    "        \"a2w_cloud_mean\", \"a2w_cloud_warmest_mean\", \"a2w_cloud_coldest_mean\",\n",
    "        \"a2w_cloud_ice_days_0\", \"a2w_cloud_ice_days_076\",\n",
    "\n",
    "        # Air2Water diff\n",
    "        \"a2w_diff_mean\", \"a2w_diff_warmest_mean\", \"a2w_diff_ice_days_0\", \"a2w_diff_ice_days_076\",\n",
    "\n",
    "        # LSTM full\n",
    "        \"lstm_mean\", \"lstm_warmest_mean\", \"lstm_coldest_mean\",\n",
    "        \"lstm_ice_days_0\", \"lstm_ice_days_076\",\n",
    "\n",
    "        # LSTM cloud\n",
    "        \"lstm_cloud_mean\", \"lstm_cloud_warmest_mean\", \"lstm_cloud_coldest_mean\",\n",
    "        \"lstm_cloud_ice_days_0\", \"lstm_cloud_ice_days_076\",\n",
    "\n",
    "        # LSTM diff\n",
    "        \"lstm_diff_mean\", \"lstm_diff_warmest_mean\", \"lstm_diff_ice_days_0\", \"lstm_diff_ice_days_076\",\n",
    "\n",
    "        # Air2Water p-values\n",
    "        \"a2w_pval_mean\", \"a2w_pval_warmest_mean\", \"a2w_pval_coldest_mean\",\n",
    "        \"a2w_pval_ice_days_0\", \"a2w_pval_ice_days_076\",\n",
    "\n",
    "        # LSTM p-values\n",
    "        \"lstm_pval_mean\", \"lstm_pval_warmest_mean\", \"lstm_pval_coldest_mean\",\n",
    "        \"lstm_pval_ice_days_0\", \"lstm_pval_ice_days_076\"\n",
    "    ])\n",
    "\n",
    "    stat_df.index.name = \"cci_lake_id\"\n",
    "    \n",
    "    if return_wl_df == False:\n",
    "        return stat_df\n",
    "    else:\n",
    "        return stat_df, a2w_full_sim, a2w_cloud_sim, lstm_full_sim, lstm_cloud_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "46e7e836-859a-49c6-b82b-7ab77db42204",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_stat_with_mhw(lake_id, period):\n",
    "    stat_df, a2w_full_sim, a2w_cloud_sim, lstm_full_sim, lstm_cloud_sim = cal_stat(lake_id, period, return_wl_df=True)\n",
    "    \n",
    "    # some lakes cannot be derived with lake heat wave events\n",
    "    a2w_full_sim = pd.read_csv(f\"{a2w_full_sim_dir}/{lake_id}.csv\", index_col=0, parse_dates=True).loc[period]\n",
    "    try:\n",
    "        a2w_full_sim_lhw_n_events, a2w_full_sim_lhw_intensity, a2w_full_sim_lhw_duration = cal_mhw_stats(a2w_full_sim)\n",
    "        a2w_cloud_sim_lhw_n_events, a2w_cloud_sim_lhw_intensity, a2w_cloud_sim_lhw_duration = cal_mhw_stats(a2w_cloud_sim)\n",
    "        lstm_full_sim_lhw_n_events, lstm_full_sim_lhw_intensity, lstm_full_sim_lhw_duration = cal_mhw_stats(lstm_full_sim)\n",
    "        lstm_cloud_sim_lhw_n_events, lstm_cloud_sim_lhw_intensity, lstm_cloud_sim_lhw_duration = cal_mhw_stats(lstm_cloud_sim)\n",
    "    except:\n",
    "        a2w_full_sim_lhw_n_events, a2w_full_sim_lhw_intensity, a2w_full_sim_lhw_duration = np.nan, np.nan, np.nan\n",
    "        a2w_cloud_sim_lhw_n_events, a2w_cloud_sim_lhw_intensity, a2w_cloud_sim_lhw_duration = np.nan, np.nan, np.nan\n",
    "        lstm_full_sim_lhw_n_events, lstm_full_sim_lhw_intensity, lstm_full_sim_lhw_duration = np.nan, np.nan, np.nan\n",
    "        lstm_cloud_sim_lhw_n_events, lstm_cloud_sim_lhw_intensity, lstm_cloud_sim_lhw_duration = np.nan, np.nan, np.nan\n",
    "        \n",
    "    # load to stat_df\n",
    "    stat_df.loc[lake_id, \n",
    "                [\"a2w_lhw_n_events\", \"a2w_lhw_intensity\", \"a2w_lhw_duration\",\n",
    "                 \"a2w_cloud_lhw_n_events\", \"a2w_cloud_lhw_intensity\", \"a2w_cloud_lhw_duration\",\n",
    "                 \"lstm_lhw_n_events\", \"lstm_lhw_intensity\", \"lstm_lhw_duration\",\n",
    "                 \"lstm_cloud_lhw_n_events\", \"lstm_cloud_lhw_intensity\", \"lstm_cloud_lhw_duration\"]] = [a2w_full_sim_lhw_n_events, a2w_full_sim_lhw_intensity, a2w_full_sim_lhw_duration,\n",
    "                                                                                                       a2w_cloud_sim_lhw_n_events, a2w_cloud_sim_lhw_intensity, a2w_cloud_sim_lhw_duration,\n",
    "                                                                                                       lstm_full_sim_lhw_n_events, lstm_full_sim_lhw_intensity, lstm_full_sim_lhw_duration,\n",
    "                                                                                                       lstm_cloud_sim_lhw_n_events, lstm_cloud_sim_lhw_intensity, lstm_cloud_sim_lhw_duration,\n",
    "                                                                                                      ]\n",
    "    return stat_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4614a617-415b-4346-b35d-000525953713",
   "metadata": {},
   "source": [
    "It looks like the heat wave metric does not apply to arctic lakes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7e04e68a-ddcd-458d-adb0-21e307b4b722",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2016/2016 [00:19<00:00, 101.42it/s]\n",
      "100%|██████████| 2016/2016 [00:12<00:00, 162.70it/s]\n"
     ]
    }
   ],
   "source": [
    "train_stats = pd.concat(p_map(partial(cal_stat, period = train_period), cci_lake_list), axis = 0)\n",
    "val_stats = pd.concat(p_map(partial(cal_stat, period = val_period), cci_lake_list), axis = 0)\n",
    "train_stats.to_csv(\"data/sim_stats_trainperiod_ensemble_mean.csv\")\n",
    "val_stats.to_csv(\"data/sim_stats_valperiod_ensemble_mean.csv\")\n",
    "# total_stats = pd.concat(p_map(partial(cal_stat, period = total_period), cci_lake_list), axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7db9c4e9-e5c1-4417-acc7-2930840692dd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2016/2016 [06:31<00:00,  5.15it/s]\n"
     ]
    }
   ],
   "source": [
    "# train_stats = pd.concat(p_map(partial(cal_stat_with_mhw, period = train_period), cci_lake_list), axis = 0)\n",
    "# val_stats = pd.concat(p_map(partial(cal_stat_with_mhw, period = val_period), cci_lake_list), axis = 0)\n",
    "total_stats = pd.concat(p_map(partial(cal_stat_with_mhw, period = total_period), cci_lake_list), axis = 0)\n",
    "total_stats.to_csv(\"data/sim_stats_totalperiod_ensemble_mean.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf27d608-3e1c-4adf-ada6-98feb2740682",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-laketemp]",
   "language": "python",
   "name": "conda-env-.conda-laketemp-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
