{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a11d2b2-9e05-4f49-8755-26ea60e51cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from pathlib import Path\n",
    "from typing import Tuple, List\n",
    "import matplotlib.pyplot as plt\n",
    "from numba import njit\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import tqdm\n",
    "import os\n",
    "os.chdir(\"/work/pi_kandread_umass_edu/lake_temp_bias/satbias_model/satlswt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dea822b7-188d-4e35-a86e-10ea94720400",
   "metadata": {},
   "outputs": [],
   "source": [
    "# File paths\n",
    "job = 10\n",
    "ensemble_num = 10\n",
    "lake_id_list = pd.read_csv(\"data/cci_lakes_hydrolake_depth.csv\")[\"CCI ID\"].to_numpy()\n",
    "cci_lake_id = str(lake_id_list[job])\n",
    "param_dir = \"/nas/cee-hydro/laketemp_bias/params/lstm_param_full\"\n",
    "sim_dir = \"/nas/cee-hydro/laketemp_bias/simulations/lstm_full_sim\"\n",
    "air_temp_path = \"/nas/cee-hydro/laketemp_bias/era5land/air_temp.csv\"\n",
    "wind_path = \"/nas/cee-hydro/laketemp_bias/era5land/wind.csv\"\n",
    "srad_path = \"/nas/cee-hydro/laketemp_bias/era5land/srad.csv\"\n",
    "water_temp_path = \"/nas/cee-hydro/laketemp_bias/era5land/water_temp.csv\"\n",
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "#train sim period\n",
    "train_period = (pd.to_datetime(\"2003-01-01\", format=\"%Y-%m-%d\"), \n",
    "                pd.to_datetime(\"2017-12-31\", format=\"%Y-%m-%d\"))\n",
    "sim_period = (pd.to_datetime(\"2001-01-01\", format=\"%Y-%m-%d\"), # needs 365 days in advance\n",
    "              pd.to_datetime(\"2023-12-31\", format=\"%Y-%m-%d\"))\n",
    "#hyperparameters\n",
    "hidden_size = 10 # Number of LSTM cells\n",
    "dropout_rate = 0.0 # Dropout rate of the final fully connected Layer [0.0, 1.0]\n",
    "sequence_length = 365 # Length of the meteorological record provided to the network\n",
    "batch_size = 2048\n",
    "\n",
    "# preload the weather dataframe\n",
    "# ========================================== preload forcing ==========================================\n",
    "def load_forcing(lake_id):\n",
    "    # load weather data\n",
    "    df_air = pd.read_csv(air_temp_path, index_col=0, parse_dates=True, usecols=[\"Unnamed: 0\", str(lake_id)])\n",
    "    df_wind = pd.read_csv(wind_path, index_col=0, parse_dates=True, usecols=[\"Unnamed: 0\", str(lake_id)])\n",
    "    df_srad = pd.read_csv(srad_path, index_col=0, parse_dates=True, usecols=[\"Unnamed: 0\", str(lake_id)])\n",
    "    # load weather data\n",
    "    weather_df = pd.concat([df_air, df_wind, df_srad], axis = 1)\n",
    "    weather_df.columns = [\"ta\", \"wind\", \"srad\"]\n",
    "    return weather_df\n",
    "\n",
    "# preload the water temperature\n",
    "def load_water_temp(lake_id):\n",
    "    # load water temperature\n",
    "    twdf = pd.read_csv(water_temp_path,\n",
    "                     index_col=0, parse_dates=True, usecols=[\"Unnamed: 0\", str(lake_id)]).clip(0, 999)\n",
    "    twdf.columns = [\"tw\"]\n",
    "    return twdf.tw\n",
    "\n",
    "# lake dataframe\n",
    "total_df = load_forcing(cci_lake_id)\n",
    "total_df['tw'] = load_water_temp(cci_lake_id)\n",
    "\n",
    "@njit\n",
    "def reshape_data(x: np.ndarray, y: np.ndarray, seq_length: int) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Reshape matrix data into sample shape for LSTM training.\n",
    "\n",
    "    :param x: Matrix containing input features column wise and time steps row wise\n",
    "    :param y: Matrix containing the output feature.\n",
    "    :param seq_length: Length of look back days for one day of prediction\n",
    "\n",
    "    :return: Two np.ndarrays, the first of shape (samples, length of sequence,\n",
    "        number of features), containing the input data for the LSTM. The second\n",
    "        of shape (samples, 1) containing the expected output for each input\n",
    "        sample.\n",
    "    \"\"\"\n",
    "    num_samples, num_features = x.shape\n",
    "\n",
    "    x_new = np.zeros((num_samples - seq_length + 1, seq_length, num_features))\n",
    "    y_new = np.zeros((num_samples - seq_length + 1, 1))\n",
    "\n",
    "    for i in range(0, x_new.shape[0]):\n",
    "        x_new[i, :, :num_features] = x[i:i + seq_length, :]\n",
    "        y_new[i, :] = y[i + seq_length - 1, 0]\n",
    "\n",
    "    return x_new, y_new\n",
    "\n",
    "class laketemp(Dataset):\n",
    "    def __init__(self, \n",
    "                 lake_id: str,\n",
    "                 total_df: pd.DataFrame=None, # combination of weather and obs water temperature\n",
    "                 seq_length: int=sequence_length,\n",
    "                 period: str=None,\n",
    "                 dates: List=None, \n",
    "                 means: pd.Series=None, \n",
    "                 stds: pd.Series=None):\n",
    "        self.lake_id = lake_id\n",
    "        self.seq_length = seq_length\n",
    "        self.period = period\n",
    "        self.dates = dates\n",
    "        self.means = means\n",
    "        self.stds = stds\n",
    "\n",
    "        # load datafrmae\n",
    "        self.total_df = total_df\n",
    "        # load data into memory\n",
    "        self.x, self.y = self._load_data()\n",
    "\n",
    "        # store number of samples as class attribute\n",
    "        self.num_samples = self.x.shape[0]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_samples\n",
    "\n",
    "    def __getitem__(self, idx: int):\n",
    "        return self.x[idx], self.y[idx]\n",
    "\n",
    "    def _load_data(self):\n",
    "        \"\"\"Load input and output data from text files.\"\"\"\n",
    "        df = self.total_df\n",
    "\n",
    "        if self.dates is not None:\n",
    "            # If meteorological observations exist before start date\n",
    "            # use these as well. Similiar to hydrological warmup period.\n",
    "            if self.dates[0] - pd.DateOffset(days=self.seq_length) > df.index[0]:\n",
    "                start_date = self.dates[0] - pd.DateOffset(days=self.seq_length)\n",
    "            else:\n",
    "                start_date = self.dates[0]\n",
    "            df = df[start_date:self.dates[1]]\n",
    "\n",
    "        # if training period store means and stds\n",
    "        if self.period == 'train':\n",
    "            self.means = df.mean()\n",
    "            self.stds = df.std()\n",
    "\n",
    "        # extract input and output features from DataFrame\n",
    "        x = np.array([df['ta'].values,\n",
    "                      df['wind'].values,\n",
    "                      df['srad'].values,\n",
    "                      ]).T\n",
    "        y = np.array([df['tw'].values]).T\n",
    "\n",
    "        # normalize data, reshape for LSTM training and remove invalid samples\n",
    "        x = self._local_normalization(x, variable='inputs')\n",
    "        x, y = reshape_data(x, y, self.seq_length)\n",
    "\n",
    "        if self.period == \"train\":\n",
    "            # Delete all samples, where discharge is NaN\n",
    "            if np.sum(np.isnan(y)) > 0:\n",
    "                print(f\"Deleted some records because of NaNs {self.lake_id}\")\n",
    "                x = np.delete(x, np.argwhere(np.isnan(y)), axis=0)\n",
    "                y = np.delete(y, np.argwhere(np.isnan(y)), axis=0)\n",
    "\n",
    "            # Deletes all records, where no discharge was measured (-999)\n",
    "            x = np.delete(x, np.argwhere(y < 0)[:, 0], axis=0)\n",
    "            y = np.delete(y, np.argwhere(y < 0)[:, 0], axis=0)\n",
    "\n",
    "            # normalize discharge\n",
    "            y = self._local_normalization(y, variable='output')\n",
    "\n",
    "        # convert arrays to torch tensors\n",
    "        x = torch.from_numpy(x.astype(np.float32))\n",
    "        y = torch.from_numpy(y.astype(np.float32))\n",
    "\n",
    "        return x, y\n",
    "\n",
    "    def _local_normalization(self, feature: np.ndarray, variable: str) -> \\\n",
    "            np.ndarray:\n",
    "        \"\"\"Normalize input/output features with local mean/std.\n",
    "\n",
    "        :param feature: Numpy array containing the feature(s) as matrix.\n",
    "        :param variable: Either 'inputs' or 'output' showing which feature will\n",
    "            be normalized\n",
    "        :return: array containing the normalized feature\n",
    "        \"\"\"\n",
    "        if variable == 'inputs':\n",
    "            means = np.array([self.means['ta'],\n",
    "                              self.means['wind'],\n",
    "                              self.means['srad']])\n",
    "            stds = np.array([self.stds['ta'],\n",
    "                             self.stds['wind'],\n",
    "                             self.stds['srad']])\n",
    "            feature = (feature - means) / stds\n",
    "        elif variable == 'output':\n",
    "            feature = ((feature - self.means[\"tw\"]) /\n",
    "                       self.stds[\"tw\"])\n",
    "        else:\n",
    "            raise RuntimeError(f\"Unknown variable type {variable}\")\n",
    "\n",
    "        return feature\n",
    "\n",
    "    def local_rescale(self, feature: np.ndarray, variable: str) -> \\\n",
    "            np.ndarray:\n",
    "        \"\"\"Rescale input/output features with local mean/std.\n",
    "\n",
    "        :param feature: Numpy array containing the feature(s) as matrix.\n",
    "        :param variable: Either 'inputs' or 'output' showing which feature will\n",
    "            be normalized\n",
    "        :return: array containing the normalized feature\n",
    "        \"\"\"\n",
    "        if variable == 'inputs':\n",
    "            means = np.array([self.means['ta'],\n",
    "                              self.means['wind'],\n",
    "                              self.means['srad']])\n",
    "            stds = np.array([self.stds['ta'],\n",
    "                             self.stds['wind'],\n",
    "                             self.stds['srad']])\n",
    "            feature = feature * stds + means\n",
    "        elif variable == 'output':\n",
    "            feature = (feature * self.stds[\"tw\"] +\n",
    "                       self.means[\"tw\"])\n",
    "        else:\n",
    "            raise RuntimeError(f\"Unknown variable type {variable}\")\n",
    "\n",
    "        return feature\n",
    "\n",
    "    def get_means(self):\n",
    "        return self.means\n",
    "\n",
    "    def get_stds(self):\n",
    "        return self.stds\n",
    "\n",
    "class Model(nn.Module):\n",
    "    \"\"\"Implementation of a single layer LSTM network\"\"\"\n",
    "\n",
    "    def __init__(self, hidden_size: int, dropout_rate: float=0.0, normalized_zero: float = 0.0):\n",
    "        \"\"\"Initialize model\n",
    "\n",
    "        :param hidden_size: Number of hidden units/LSTM cells\n",
    "        :param dropout_rate: Dropout rate of the last fully connected\n",
    "            layer. Default 0.0\n",
    "        \"\"\"\n",
    "        super(Model, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.dropout_rate = dropout_rate\n",
    "\n",
    "        # create required layer\n",
    "        self.lstm = nn.LSTM(input_size=3, hidden_size=self.hidden_size, \n",
    "                            num_layers=1, bias=True, batch_first=True)\n",
    "        self.dropout = nn.Dropout(p=self.dropout_rate)\n",
    "        self.fc = nn.Linear(in_features=self.hidden_size, out_features=1)\n",
    "        self.normalized_zero = normalized_zero\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Forward pass through the Network.\n",
    "\n",
    "        :param x: Tensor of shape [batch size, seq length, num features]\n",
    "            containing the input data for the LSTM network.\n",
    "\n",
    "        :return: Tensor containing the network predictions\n",
    "        \"\"\"\n",
    "        output, (h_n, c_n) = self.lstm(x)\n",
    "\n",
    "        # perform prediction only at the end of the input sequence\n",
    "        pred = self.fc(self.dropout(h_n[-1,:,:]))\n",
    "\n",
    "        # clamp prediction of 0\n",
    "        pred = torch.clamp(pred, min = self.normalized_zero)\n",
    "\n",
    "\n",
    "        return pred\n",
    "\n",
    "\n",
    "\n",
    "def train_epoch(model, optimizer, loader, loss_func, epoch):\n",
    "    \"\"\"Train model for a single epoch.\n",
    "\n",
    "    :param model: A torch.nn.Module implementing the LSTM model\n",
    "    :param optimizer: One of PyTorchs optimizer classes.\n",
    "    :param loader: A PyTorch DataLoader, providing the trainings\n",
    "        data in mini batches.\n",
    "    :param loss_func: The loss function to minimize.\n",
    "    :param epoch: The current epoch (int) used for the progress bar\n",
    "    \"\"\"\n",
    "    # set model to train mode (important for dropout)\n",
    "    model.train()\n",
    "    pbar = tqdm.tqdm_notebook(loader)\n",
    "    pbar.set_description(f\"Epoch {epoch}\")\n",
    "    # request mini-batch of data from the loader\n",
    "    for xs, ys in pbar:\n",
    "        # delete previously stored gradients from the model\n",
    "        optimizer.zero_grad()\n",
    "        # push data to GPU (if available)\n",
    "        xs, ys = xs.to(DEVICE), ys.to(DEVICE)\n",
    "        # get model predictions\n",
    "        y_hat = model(xs)\n",
    "        # calculate loss\n",
    "        loss = loss_func(y_hat, ys)\n",
    "        # calculate gradients\n",
    "        loss.backward()\n",
    "        # update the weights\n",
    "        optimizer.step()\n",
    "        # write current loss in the progress bar\n",
    "        pbar.set_postfix_str(f\"Loss: {loss.item():.4f}\")\n",
    "\n",
    "\n",
    "def eval_model(model, loader) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "    \"\"\"Evaluate the model.\n",
    "\n",
    "    :param model: A torch.nn.Module implementing the LSTM model\n",
    "    :param loader: A PyTorch DataLoader, providing the data.\n",
    "\n",
    "    :return: Two torch Tensors, containing the observations and \n",
    "        model predictions\n",
    "    \"\"\"\n",
    "    # set model to eval mode (important for dropout)\n",
    "    model.eval()\n",
    "    obs = []\n",
    "    preds = []\n",
    "    # in inference mode, we don't need to store intermediate steps for\n",
    "    # backprob\n",
    "    with torch.no_grad():\n",
    "        # request mini-batch of data from the loader\n",
    "        for xs, ys in loader:\n",
    "            # push data to GPU (if available)\n",
    "            xs = xs.to(DEVICE)\n",
    "            # get model predictions\n",
    "            y_hat = model(xs)\n",
    "            obs.append(ys)\n",
    "            preds.append(y_hat)\n",
    "\n",
    "    return torch.cat(obs), torch.cat(preds)\n",
    "\n",
    "def calc_nse(obs: np.array, sim: np.array) -> float:\n",
    "    \"\"\"Calculate Nash-Sutcliff-Efficiency.\n",
    "\n",
    "    :param obs: Array containing the observations\n",
    "    :param sim: Array containing the simulations\n",
    "    :return: NSE value.\n",
    "    \"\"\"\n",
    "    # only consider time steps, where observations are available\n",
    "    sim = np.delete(sim, np.argwhere(obs < 0), axis=0)\n",
    "    obs = np.delete(obs, np.argwhere(obs < 0), axis=0)\n",
    "\n",
    "    # check for NaNs in observations\n",
    "    sim = np.delete(sim, np.argwhere(np.isnan(obs)), axis=0)\n",
    "    obs = np.delete(obs, np.argwhere(np.isnan(obs)), axis=0)\n",
    "\n",
    "    denominator = np.sum((obs - np.mean(obs)) ** 2)\n",
    "    numerator = np.sum((sim - obs) ** 2)\n",
    "    nse_val = 1 - numerator / denominator\n",
    "\n",
    "    return nse_val\n",
    "\n",
    "def simulate(lake_id,\n",
    "             ensemble_id, # locate parameter path\n",
    "             simulation_period = [sim_period[0], sim_period[1]],\n",
    "             hidden_size = hidden_size, # Number of LSTM cells\n",
    "             dropout_rate = dropout_rate, # Dropout rate of the final fully connected Layer [0.0, 1.0]\n",
    "             sequence_length = sequence_length, # Length of the meteorological record provided to the network\n",
    "             batch_size = batch_size, # batch size for simulation \n",
    "             train_period = [train_period[0], train_period[1]],\n",
    "            ):\n",
    "    # create a train set to get the mean and stds\n",
    "    ds_train = laketemp(lake_id, \n",
    "                        total_df,\n",
    "                        seq_length=sequence_length, \n",
    "                        period=\"train\", \n",
    "                        dates=train_period)\n",
    "\n",
    "    means = ds_train.get_means()\n",
    "    stds = ds_train.get_stds()\n",
    "\n",
    "    # simulate, use the 'eval' dataloader\n",
    "    ds_sim = laketemp(lake_id, \n",
    "                      total_df,\n",
    "                      seq_length=sequence_length, \n",
    "                      period=\"eval\", \n",
    "                      dates=simulation_period,\n",
    "                      means=means, \n",
    "                      stds=stds)\n",
    "    sim_loader = DataLoader(ds_sim, \n",
    "                            batch_size=batch_size, \n",
    "                            shuffle=False)\n",
    "    #########################\n",
    "    # Model, Optimizer, Loss#\n",
    "    #########################\n",
    "\n",
    "    normalized_zero = (0 - means[\"tw\"])/stds[\"tw\"]\n",
    "\n",
    "    # Here we create our model, feel free \n",
    "    model = Model(hidden_size=hidden_size, dropout_rate=dropout_rate, normalized_zero=normalized_zero).to(DEVICE)\n",
    "    # load parameter\n",
    "    param_path = f\"{param_dir}/{lake_id}_{ensemble_id}.pt\"\n",
    "    model.load_state_dict(torch.load(param_path, map_location=torch.device('cpu')))\n",
    "    model.eval()\n",
    "    # predict\n",
    "    obs, preds = eval_model(model, sim_loader)\n",
    "    # rescale prediction\n",
    "    preds = ds_sim.local_rescale(preds.cpu().numpy(), variable='output')\n",
    "    # create a dataframe\n",
    "    start_date = ds_sim.dates[0]\n",
    "    end_date = ds_sim.dates[1] + pd.DateOffset(days=1)    \n",
    "    date_range = pd.date_range(start_date, end_date)\n",
    "    output_df = pd.DataFrame(preds, index = date_range)\n",
    "    output_df.columns = [f\"tw_sim_{ensemble_id}\"]\n",
    "    return output_df\n",
    "\n",
    "# Run\n",
    "laketemp_df = pd.DataFrame([])\n",
    "for ensemble_id in range(ensemble_num):\n",
    "    tw_df = simulate(cci_lake_id, ensemble_id)\n",
    "    laketemp_df = pd.concat([laketemp_df, tw_df], axis = 1)\n",
    "    print(ensemble_id, \" Done\")\n",
    "# save the ensemble simulation to a csv\n",
    "# laketemp_df.to_csv(f\"{sim_dir}/{cci_lake_id}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edafd60a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  Done\n",
      "1  Done\n",
      "2  Done\n",
      "3  Done\n",
      "4  Done\n",
      "5  Done\n",
      "6  Done\n",
      "7  Done\n",
      "8  Done\n",
      "9  Done\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7bb6eed-604d-4f40-81d5-1b305f514acc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-pytorch]",
   "language": "python",
   "name": "conda-env-.conda-pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
